# 迭代精炼训练配置文件

data:
  train_files: data/train.parquet  # 训练数据路径（相对于项目根目录）
  val_files: data/val.parquet      # 验证数据路径（相对于项目根目录）
  prompt_key: prompt                  # parquet 文件中的 prompt 列名（支持字符串或消息列表）
  response_key: target                # parquet 文件中的 response 列名（支持字符串或消息列表）
  max_length: 2048                    # 最大序列长度
  truncation: right                   # 截断策略: error | left | right
  micro_batch_size_per_gpu: 2         # 每个 GPU 的微批次大小
  pad_token_id: null                  # null 表示使用 tokenizer 的 pad_token_id

model:
  partial_pretrain: meta-llama/Llama-3-8B  # 预训练模型路径或 HuggingFace 模型名
  trust_remote_code: false                  # 是否信任远程代码
  enable_gradient_checkpointing: false      # 是否启用梯度检查点（节省显存但增加计算）
  tensor_parallel_size: 1                   # Tensor Parallel 大小（1=不使用，2/4=使用TP）
  fsdp_config:
    wrap_policy:
      min_num_params: 0                     # FSDP 包装策略的最小参数数量
    cpu_offload: false                      # 是否将参数卸载到 CPU

optim:
  lr: 1e-5                             # 学习率
  betas: [0.9, 0.95]                   # AdamW beta 参数
  weight_decay: 0.01                   # 权重衰减
  warmup_steps_ratio: 0.05             # 预热步数占总步数的比例
  clip_grad: 1.0                       # 梯度裁剪阈值
  gradient_accumulation_steps: 64      # 梯度累积步数（4 GPUs × 2 batch_size × 64 = 512 样本/更新）

trainer:
  default_local_dir: ./checkpoints/iterative_refine  # 本地检查点目录
  default_hdfs_dir: null                             # HDFS 备份目录（可选）
  project_name: iterative-refine-sft                 # WandB/TensorBoard 项目名
  experiment_name: llama3-8b-test                    # 实验名称
  total_epochs: 3                                    # 总 epoch 数
  save_checkpoint_steps: 1000                        # 每 N 步保存检查点
  max_ckpt_to_keep: 3                                # 最多保留几个检查点（null=保留所有）
  max_debug_steps: null                              # 调试模式最大步数（null=不限制，用于调试）
  logger: ['console', 'wandb']                       # 日志记录器: console, wandb, tensorboard

  # Resume 相关配置 (参考 VERL)
  resume_mode: auto                                  # auto: 自动查找最新checkpoint; disable: 从头训练; resume_path: 从指定路径恢复
  resume_from_path: null                             # 指定恢复的 checkpoint 路径（仅当 resume_mode='resume_path' 或 'auto' 时生效）

  # Checkpoint 内容配置
  checkpoint:
    save_contents: ['model', 'optimizer', 'extra', 'hf_model']   # 保存内容: model, optimizer, extra (lr_scheduler + rng)
    load_contents: ['model', 'optimizer', 'extra']   # 加载内容

# 迭代精炼特有的配置
iterative:
  num_iterations: 2                    # 迭代轮数（s0, s1, ...）
  noise_min: 0.1                       # 最小噪声比例
  noise_max: 0.9                       # 最大噪声比例
  loss_weights: [1.0, 1.0]             # 每一轮 loss 的权重 [loss_s0, loss_s1, ...]
