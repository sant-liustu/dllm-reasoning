# 交错训练配置文件（Interleaved SFT Training）

data:
  train_files: /data/v-zihaliu/amlt-RLF-ExpConfig/Dream/data/openr1.parquet  # 训练数据路径（绝对路径）
  val_files: null                        # 验证数据路径（null=不使用验证集）
  prompt_key: prompt                     # parquet 文件中的 prompt 列名（支持字符串或消息列表）
  response_key: target                   # parquet 文件中的 response 列名（支持字符串或消息列表）
  max_length: 2048                       # 最大序列长度
  block_size: 4                          # 每个 block 的 token 数量（Next Block Prediction）
  truncation: right                      # 截断策略: error | left | right
  micro_batch_size_per_gpu: 2            # 每个 GPU 的微批次大小
  pad_token_id: null                     # null 表示使用 tokenizer 的 pad_token_id

model:
  partial_pretrain: /data/v-zihaliu/amlt-RLF-ExpConfig/Dream/dllm_reasoning/dllm_reasoning/model/DLLM-1.5B  # 预训练模型路径（绝对路径）
  trust_remote_code: true                # 是否信任远程代码（DLLM 需要）
  enable_gradient_checkpointing: true    # 是否启用梯度检查点（节省显存但增加计算）
  tensor_parallel_size: 1                # Tensor Parallel 大小（1=不使用，2/4=使用TP）
  fsdp_config:
    wrap_policy:
      min_num_params: 0                  # FSDP 包装策略的最小参数数量
    cpu_offload: false                   # 是否将参数卸载到 CPU

optim:
  lr: 1e-5                               # 学习率
  betas: [0.9, 0.95]                     # AdamW beta 参数
  weight_decay: 0.01                     # 权重衰减
  warmup_steps_ratio: 0.05               # 预热步数占总步数的比例
  clip_grad: 1.0                         # 梯度裁剪阈值
  gradient_accumulation_steps: 64        # 梯度累积步数（4 GPUs × 2 batch_size × 64 = 512 样本/更新）

trainer:
  default_local_dir: ./checkpoints/interleaved_sft  # 本地检查点目录
  default_hdfs_dir: null                            # HDFS 备份目录（可选）
  project_name: interleaved-sft                     # WandB/TensorBoard 项目名
  experiment_name: dllm-1.5b-openr1                 # 实验名称
  total_epochs: 3                                   # 总 epoch 数
  save_checkpoint_steps: 1000                       # 每 N 步保存检查点
  max_ckpt_to_keep: 3                               # 最多保留几个检查点（null=保留所有）
  max_debug_steps: null                             # 调试模式最大步数（null=不限制，用于调试）
  logger: ['console', 'wandb']                      # 日志记录器: console, wandb, tensorboard

  # Resume 相关配置 (参考 VERL)
  resume_mode: auto                                 # auto: 自动查找最新checkpoint; disable: 从头训练; resume_path: 从指定路径恢复
  resume_from_path: null                            # 指定恢复的 checkpoint 路径（仅当 resume_mode='resume_path' 或 'auto' 时生效）

  # Checkpoint 内容配置
  checkpoint:
    save_contents: ['model', 'optimizer', 'extra', 'hf_model']   # 保存内容: model, optimizer, extra (lr_scheduler + rng)
    load_contents: ['model', 'optimizer', 'extra']   # 加载内容
