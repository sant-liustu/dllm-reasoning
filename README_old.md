# dLLM Reasoning: è¿­ä»£ç²¾ç‚¼è®­ç»ƒæ¡†æ¶

## æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªåŸºäº**è¿­ä»£ç²¾ç‚¼ï¼ˆIterative Refinementï¼‰**ç­–ç•¥çš„ SFT è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºè®­ç»ƒæ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆdLLMï¼‰è¿›è¡Œæ¨ç†ä»»åŠ¡ã€‚

### æ ¸å¿ƒæ€æƒ³

ä¸ä¼ ç»Ÿçš„ Dream æ¨¡å‹ä¸åŒï¼Œæœ¬æ¡†æ¶ï¼š
1. âœ… **ä¸ä¿®æ”¹æ¨¡å‹æ¶æ„** - ä½¿ç”¨æ ‡å‡†çš„å› æœ AR æ¨¡å‹ï¼ˆä¸éœ€è¦åŒå‘æ³¨æ„åŠ›ï¼‰
2. âœ… **è¿­ä»£ç²¾ç‚¼è®­ç»ƒ** - å¤šè½®å‰å‘ä¼ æ’­ï¼Œé€æ­¥ç²¾ç‚¼ç”Ÿæˆè´¨é‡
3. âœ… **åªå¯¹ response åŠ å™ª** - instruction åŒºåŸŸä¿æŒä¸å˜
4. âœ… **ä½¿ç”¨ EOS token åŠ å™ª** - è€Œéç‰¹æ®Šçš„ MASK token

### è®­ç»ƒæµç¨‹

```
åŸå§‹æ•°æ® (t0):
  instruction + response

â†“ ç¬¬ä¸€è½®

åŠ å™ª (s0):
  instruction + noisy_response (éƒ¨åˆ† token æ›¿æ¢ä¸º EOS)

â†“

å‰å‘ä¼ æ’­:
  logits_s0 = model(s0)

â†“

è®¡ç®— loss:
  loss_s0 = CrossEntropy(logits_s0, t0)  # å¯¹åŸå§‹ t0 è®¡ç®—
  ã€æ³¨æ„ã€‘åªåœ¨ response åŒºåŸŸè®¡ç®— loss

â†“

è´ªå©ªè§£ç :
  s1 = greedy_decode(logits_s0)  # åªåœ¨ response åŒºåŸŸè§£ç 

â†“ ç¬¬äºŒè½®

å‰å‘ä¼ æ’­:
  logits_s1 = model(s1)

â†“

è®¡ç®— loss:
  loss_s1 = CrossEntropy(logits_s1, t0)  # ä»ç„¶å¯¹åŸå§‹ t0 è®¡ç®—

â†“

èšåˆ loss:
  total_loss = loss_s0 + loss_s1

â†“

æ¢¯åº¦æ›´æ–°:
  total_loss.backward()
  optimizer.step()
```

---

## ç›®å½•ç»“æ„

```
dllm_reasoning/
â”œâ”€â”€ README.md                          # æœ¬æ–‡ä»¶
â”œâ”€â”€ train_iterative_refine.py          # ä¸»è®­ç»ƒè„šæœ¬
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ iterative_refine.yaml          # è®­ç»ƒé…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ trainer/
â”‚   â”œâ”€â”€ sft_dataset.py                 # æ•°æ®é›†ç±»ï¼ˆä» Dream å¤åˆ¶ï¼‰
â”‚   â””â”€â”€ iterative_refine_trainer.py    # è¿­ä»£ç²¾ç‚¼è®­ç»ƒå™¨ä¸»ç±»
â”‚
â”œâ”€â”€ losses/
â”‚   â””â”€â”€ iterative_loss.py              # Loss è®¡ç®—å‡½æ•°
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ noise_utils.py                 # åŠ å™ªã€è§£ç ç­‰å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ inference/                         # ğŸ†• æ¨ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py                   # æ ¸å¿ƒï¼šiterative_generate å‡½æ•°
â”‚   â””â”€â”€ demo.py                        # æ¨ç†æ¼”ç¤ºè„šæœ¬
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ run_train.sh                   # ä¾¿æ·å¯åŠ¨è„šæœ¬
    â””â”€â”€ verify_label_alignment.py      # Label å¯¹é½éªŒè¯è„šæœ¬
```

---

## å®‰è£…

### 1. æ¿€æ´»ç¯å¢ƒ

```bash
conda activate dllm_zihan  # æˆ–ä½ åˆ›å»ºçš„å…¶ä»–ç¯å¢ƒ
```

### 2. ç¡®ä¿ä¾èµ–å·²å®‰è£…

å…³é”®ä¾èµ–ï¼š
- âœ… PyTorch 2.5.1
- âœ… Transformers 4.57.1
- âœ… VERL 0.7.0.dev0
- âœ… Hydra 1.3.2
- âœ… TensorDict 0.10.0

å¦‚æœè¿˜æ²¡å®‰è£… VERLï¼Œè¯·å‚è€ƒé¡¹ç›®æ ¹ç›®å½•çš„ `ENVIRONMENT_SETUP.md`ã€‚

---

## å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

æ•°æ®æ ¼å¼ï¼š**Parquet æ–‡ä»¶**ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `instruction`: æŒ‡ä»¤æ–‡æœ¬
- `output`: æœŸæœ›çš„è¾“å‡º

ç¤ºä¾‹ï¼š
```python
import pandas as pd

data = [
    {"instruction": "What is 2+2?", "output": "2+2 equals 4."},
    {"instruction": "Explain gravity", "output": "Gravity is a fundamental force..."},
]

df = pd.DataFrame(data)
df.to_parquet("train.parquet", index=False)
```

### 2. ä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `dllm_reasoning/config/iterative_refine.yaml`ï¼š

```yaml
data:
  train_files: /your/path/to/train.parquet
  val_files: /your/path/to/val.parquet
  prompt_key: instruction
  response_key: output

model:
  partial_pretrain: meta-llama/Llama-3-8B  # ä½ çš„é¢„è®­ç»ƒæ¨¡å‹

trainer:
  default_local_dir: ./checkpoints/my_exp
```

### 3. å¯åŠ¨è®­ç»ƒ

#### æ–¹æ³• Aï¼šä½¿ç”¨ä¾¿æ·è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /data/v-zihaliu/amlt-RLF-ExpConfig/Dream

bash dllm_reasoning/scripts/run_train.sh 4 ./checkpoints/my_exp \
    data.train_files=/your/path/to/train.parquet \
    model.partial_pretrain=meta-llama/Llama-3-8B
```

å‚æ•°è¯´æ˜ï¼š
- `4`: ä½¿ç”¨ 4 ä¸ª GPU
- `./checkpoints/my_exp`: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
- åç»­å‚æ•°ï¼šè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®

#### æ–¹æ³• Bï¼šç›´æ¥ä½¿ç”¨ torchrun

```bash
cd /data/v-zihaliu/amlt-RLF-ExpConfig/Dream

torchrun --standalone --nnodes=1 --nproc_per_node=4 \
    -m dllm_reasoning.train_iterative_refine \
    data.train_files=/your/path/to/train.parquet \
    model.partial_pretrain=meta-llama/Llama-3-8B \
    trainer.default_local_dir=./checkpoints/my_exp
```

---

## æ ¸å¿ƒé…ç½®è¯´æ˜

### è¿­ä»£é…ç½® (`iterative` éƒ¨åˆ†)

```yaml
iterative:
  num_iterations: 2          # è¿­ä»£è½®æ•°ï¼ˆé»˜è®¤ 2ï¼šs0 â†’ s1ï¼‰
  noise_min: 0.1             # æœ€å°å™ªå£°æ¯”ä¾‹ï¼ˆ10% token è¢«æ›¿æ¢ï¼‰
  noise_max: 0.9             # æœ€å¤§å™ªå£°æ¯”ä¾‹ï¼ˆ90% token è¢«æ›¿æ¢ï¼‰
  loss_weights: [1.0, 1.0]   # æ¯è½® loss çš„æƒé‡
```

**è°ƒæ•´å»ºè®®**ï¼š
- **æ›´å¤šè½®æ¬¡**ï¼š`num_iterations: 3` æˆ– `4`ï¼ˆéœ€è¦æ›´å¤šæ˜¾å­˜ï¼‰
- **æ›´å°‘å™ªå£°**ï¼š`noise_max: 0.5`ï¼ˆæ›´æ¸©å’Œçš„è®­ç»ƒï¼‰
- **åŠ æƒç­–ç•¥**ï¼š`loss_weights: [0.5, 1.0]`ï¼ˆæ›´é‡è§†åç»­è½®æ¬¡ï¼‰

### è®­ç»ƒé…ç½® (`trainer` éƒ¨åˆ†)

```yaml
trainer:
  total_epochs: 3
  save_checkpoint_steps: 1000
  logger: ['console', 'wandb']  # æ—¥å¿—åç«¯
```

### ä¼˜åŒ–å™¨é…ç½® (`optim` éƒ¨åˆ†)

```yaml
optim:
  lr: 2e-5                    # å­¦ä¹ ç‡
  warmup_steps_ratio: 0.1     # warmup æ¯”ä¾‹
  clip_grad: 1.0              # æ¢¯åº¦è£å‰ª
```

---

## éªŒè¯ Label å¯¹é½

è¿è¡ŒéªŒè¯è„šæœ¬ç¡®ä¿ loss è®¡ç®—æ­£ç¡®ï¼ˆnext token predictionï¼‰ï¼š

```bash
python dllm_reasoning/scripts/verify_label_alignment.py
```

é¢„æœŸè¾“å‡ºï¼š
```
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼

ç¡®è®¤ï¼š
  âœ… Label å¯¹é½æ­£ç¡®ï¼ˆnext token predictionï¼‰
  âœ… Response mask æ­£ç¡®åº”ç”¨
  âœ… Shift æ“ä½œå®ç°æ­£ç¡®
```

---

## ä¸ Dream çš„ä¸»è¦åŒºåˆ«

| ç‰¹æ€§ | Dream | æœ¬æ¡†æ¶ (dLLM Reasoning) |
|------|-------|------------------------|
| **æ¨¡å‹æ¶æ„** | åŒå‘æ³¨æ„åŠ›ï¼ˆä¿®æ”¹æ¨¡å‹ï¼‰ | æ ‡å‡†å› æœ AR æ¨¡å‹ï¼ˆä¸ä¿®æ”¹ï¼‰ |
| **è®­ç»ƒæ–¹å¼** | å•è½®å‰å‘ä¼ æ’­ | å¤šè½®å‰å‘ä¼ æ’­ï¼ˆè¿­ä»£ç²¾ç‚¼ï¼‰ |
| **åŠ å™ªä½ç½®** | å…¨åºåˆ— | åªå¯¹ response åŒºåŸŸ |
| **åŠ å™ª Token** | MASK token | EOS token |
| **Loss è®¡ç®—** | é¢„æµ‹è¢« mask çš„ token | æ¯è½®éƒ½å¯¹åŸå§‹ token è®¡ç®— next token prediction |
| **æ¢¯åº¦æ›´æ–°** | æ¯è½®ä¸€æ¬¡ | å¤šè½®èšåˆåä¸€æ¬¡ |

---

## è®­ç»ƒç›‘æ§

### æŸ¥çœ‹æ—¥å¿—

è®­ç»ƒæ—¶ä¼šè¾“å‡ºä»¥ä¸‹æŒ‡æ ‡ï¼š

```
train/loss_s0: ç¬¬ä¸€è½®çš„ loss
train/loss_s1: ç¬¬äºŒè½®çš„ loss
train/loss_total: æ€» lossï¼ˆåŠ æƒèšåˆï¼‰
train/grad_norm: æ¢¯åº¦èŒƒæ•°
train/lr: å½“å‰å­¦ä¹ ç‡
train/noise_mean: å¹³å‡å™ªå£°æ¯”ä¾‹
```

### ä½¿ç”¨ WandB

é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ï¼š
```yaml
trainer:
  logger: ['console', 'wandb']
  project_name: my-project
  experiment_name: my-exp-001
```

ç™»å½• WandB è´¦å·ï¼š
```bash
wandb login
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è°ƒæ•´æ˜¾å­˜å ç”¨ï¼Ÿ

**é€‰é¡¹ A**ï¼šå‡å° batch size
```yaml
data:
  micro_batch_size_per_gpu: 2  # ä» 4 æ”¹ä¸º 2
```

**é€‰é¡¹ B**ï¼šå¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
```yaml
model:
  enable_gradient_checkpointing: true
```

**é€‰é¡¹ C**ï¼šå‡å°‘è¿­ä»£è½®æ•°
```yaml
iterative:
  num_iterations: 1  # åªç”¨ä¸€è½®ï¼ˆé€€åŒ–ä¸ºæ ‡å‡† SFTï¼‰
```

### Q2: å¦‚ä½•æ£€æŸ¥ EOS tokenï¼Ÿ

```bash
python << EOF
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3-8B")
print(f"EOS token: {tokenizer.eos_token}")
print(f"EOS token ID: {tokenizer.eos_token_id}")
EOF
```

### Q3: å¦‚ä½•æ–­ç‚¹ç»­è®­ï¼Ÿ

ç›®å‰å°šæœªå®ç°è‡ªåŠ¨æ–­ç‚¹ç»­è®­ã€‚ä½ å¯ä»¥æ‰‹åŠ¨æŒ‡å®šæ£€æŸ¥ç‚¹ï¼š

```bash
# TODO: å®ç°æ–­ç‚¹ç»­è®­åŠŸèƒ½
```

### Q4: è®­ç»ƒé€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ

**å¯èƒ½åŸå› **ï¼š
1. å¤šè½®å‰å‘ä¼ æ’­å¢åŠ äº†è®¡ç®—é‡ï¼ˆè¿™æ˜¯è®¾è®¡ç‰¹ç‚¹ï¼‰
2. æ¢¯åº¦æ£€æŸ¥ç‚¹å¼€å¯ï¼ˆèŠ‚çœæ˜¾å­˜ä½†å¢åŠ è®¡ç®—ï¼‰
3. åºåˆ—é•¿åº¦è¿‡é•¿

**ä¼˜åŒ–å»ºè®®**ï¼š
1. å‡å°‘ `num_iterations`
2. å…³é—­æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæ˜¾å­˜å¤Ÿç”¨ï¼‰
3. ä½¿ç”¨æ›´å°çš„ `max_length`

---

## ä»£ç å¤ç”¨è¯´æ˜

æœ¬æ¡†æ¶å¤ç”¨äº†ä»¥ä¸‹ Dream å’Œ VERL çš„ä»£ç ï¼š

### ä» Dream å¤ç”¨ï¼š
- âœ… `trainer/sft_dataset.py` - æ•°æ®é›†ç±»
- âœ… `utils/noise_utils.py:q_sample` - åŠ å™ªå‡½æ•°

### ä» VERL å¤ç”¨ï¼š
- âœ… `verl.utils.distributed` - åˆ†å¸ƒå¼åˆå§‹åŒ–
- âœ… `verl.utils.fsdp_utils` - FSDP åŒ…è£…å·¥å…·
- âœ… `verl.utils.fs` - æ–‡ä»¶ç³»ç»Ÿå·¥å…·
- âœ… `verl.utils.torch_functional` - å­¦ä¹ ç‡è°ƒåº¦å™¨
- âœ… `verl.utils.tracking` - è®­ç»ƒè¿½è¸ª

### è‡ªå·±å®ç°ï¼š
- âœ… `trainer/iterative_refine_trainer.py` - è¿­ä»£ç²¾ç‚¼è®­ç»ƒå™¨
- âœ… `losses/iterative_loss.py` - å¤šè½® loss è®¡ç®—
- âœ… `utils/noise_utils.py:greedy_decode_response` - è´ªå©ªè§£ç 

---

---

## æ¨ç†ä½¿ç”¨

è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨æ¨ç†è„šæœ¬è¿›è¡Œç”Ÿæˆã€‚

### å¿«é€Ÿå¼€å§‹

**å•ä¸ª prompt æ¨ç†:**

```bash
python -m dllm_reasoning.inference.demo \
    --model_path /path/to/checkpoint \
    --prompt "What is 2+2?"
```

**æ‰¹é‡æ¨ç†ï¼ˆä»æ–‡ä»¶ï¼‰:**

```bash
# åˆ›å»º prompts æ–‡ä»¶
cat > prompts.txt << EOF
What is 2+2?
Explain quantum physics in simple terms.
Write a Python function to sort a list.
EOF

# æ‰¹é‡æ¨ç†
python -m dllm_reasoning.inference.demo \
    --model_path /path/to/checkpoint \
    --prompts_file prompts.txt \
    --output_file results.jsonl \
    --batch_size 4
```

**ä½¿ç”¨ chat template:**

```bash
python -m dllm_reasoning.inference.demo \
    --model_path /path/to/checkpoint \
    --prompt "What is 2+2?" \
    --use_chat_template
```

### æ¨ç†å‚æ•°è¯´æ˜

**æ ¸å¿ƒå‚æ•°:**

- `--model_path`: æ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- `--prompt`: å•ä¸ª promptï¼ˆä¸ `--prompts_file` äºŒé€‰ä¸€ï¼‰
- `--prompts_file`: prompts æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªï¼ˆä¸ `--prompt` äºŒé€‰ä¸€ï¼‰
- `--use_chat_template`: è‡ªåŠ¨åº”ç”¨ tokenizer çš„ chat template

**ç”Ÿæˆå‚æ•°:**

- `--add_eos_length`: æ¯å—æ·»åŠ çš„ EOS æ•°é‡ï¼ˆé»˜è®¤ 127ï¼‰
  - å®é™…ç”Ÿæˆ `add_eos_length + 1` ä¸ª token/å—
- `--refine_iter`: æ¯å—çš„ refine è½®æ•°ï¼ˆé»˜è®¤ 2ï¼‰
- `--max_new_tokens`: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤ 1024ï¼‰
- `--max_length`: åºåˆ—æœ€å¤§é•¿åº¦ï¼ˆé»˜è®¤ 8192ï¼‰
- `--batch_size`: æ‰¹å¤§å°ï¼ˆé»˜è®¤ 1ï¼‰

**è¾“å‡ºå‚æ•°:**

- `--output_file`: è¾“å‡ºæ–‡ä»¶ï¼ˆé»˜è®¤ `inference_results.jsonl`ï¼‰
- `--max_display`: ç»ˆç«¯æ˜¾ç¤ºçš„ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰

### æ¨ç†åŸç†

ä¸è®­ç»ƒç±»ä¼¼ï¼Œæ¨ç†ä¹Ÿé‡‡ç”¨**è¿­ä»£å—çŠ¶ç”Ÿæˆ**:

```
1. æ‹¼æ¥ N ä¸ª EOS token
   [prompt][eos][eos]...[eos]  (N ä¸ª)

2. å‰å‘ä¼ æ’­ â†’ å¾—åˆ° logits
   å¯ä»¥é¢„æµ‹ N+1 ä¸ªä½ç½®ï¼ˆåˆ©ç”¨ next token predictionï¼‰

3. è§£ç ç”Ÿæˆ N+1 ä¸ªæ–° token
   [prompt][tok1][tok2]...[tok_N+1]

4. Refine M è½®ï¼ˆé»˜è®¤ 2 è½®ï¼‰
   æ¯è½®é‡æ–°å‰å‘ â†’ è§£ç  â†’ æ›´æ–°

5. æ£€æµ‹ EOS æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦
   - å¦‚æœæ–°å—ä¸­æœ‰ EOS â†’ åœæ­¢
   - å¦‚æœè¾¾åˆ° max_length â†’ åœæ­¢
   - å¦åˆ™ç»§ç»­ä¸‹ä¸€å—
```

**å…³é”®ç†è§£:**
- è®­ç»ƒæ—¶: å¯¹ response åŠ å™ª â†’ refine â†’ å­¦ä¹ æ¢å¤
- æ¨ç†æ—¶: æ‹¼æ¥ EOS å— â†’ refine â†’ ç”Ÿæˆé«˜è´¨é‡è¾“å‡º

### ç¼–ç¨‹æ¥å£

ä¹Ÿå¯ä»¥åœ¨ä»£ç ä¸­ç›´æ¥è°ƒç”¨æ¨ç†å‡½æ•°:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from dllm_reasoning.inference import iterative_generate

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("/path/to/checkpoint").cuda()
tokenizer = AutoTokenizer.from_pretrained("/path/to/checkpoint")

# å‡†å¤‡è¾“å…¥
prompt = "What is 2+2?"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids.cuda()

# ç”Ÿæˆ
output_ids = iterative_generate(
    model=model,
    input_ids=input_ids,
    eos_token_id=tokenizer.eos_token_id,
    pad_token_id=tokenizer.pad_token_id,
    add_eos_length=127,
    refine_iter=2,
    max_new_tokens=512,
)

# è§£ç 
response = tokenizer.decode(output_ids[0, input_ids.size(1):], skip_special_tokens=True)
print(response)
```

---

## TODO

- [x] ~~æ·»åŠ æ¨ç†è„šæœ¬~~ âœ… å·²å®Œæˆ
- [ ] å®ç°æ–­ç‚¹ç»­è®­åŠŸèƒ½
- [ ] æ·»åŠ éªŒè¯é›†è¯„ä¼°
- [ ] æ”¯æŒ LoRA å¾®è°ƒ
- [ ] æ·»åŠ æ›´å¤šå™ªå£°è°ƒåº¦ç­–ç•¥ï¼ˆcosineã€linear ç­‰ï¼‰
- [ ] æ”¯æŒæ›´å¤šè½®æ¬¡çš„è¿­ä»£ï¼ˆs2, s3, ...ï¼‰
- [ ] æ¨ç†æ·»åŠ  KV Cache ä¼˜åŒ–
- [ ] æ¨ç†æ·»åŠ é‡‡æ ·åŠŸèƒ½ï¼ˆtemperatureã€top-pï¼‰

---

## å¼•ç”¨

å¦‚æœä½ ä½¿ç”¨äº†æœ¬æ¡†æ¶ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{dllm_reasoning_2025,
  title={dLLM Reasoning: Iterative Refinement Training Framework},
  author={Your Name},
  year={2025}
}
```

---

**æœ€åæ›´æ–°**: 2025-11-11
**ç‰ˆæœ¬**: 1.1.0 (æ–°å¢æ¨ç†åŠŸèƒ½)
**è®¸å¯**: Apache 2.0
