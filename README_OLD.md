# dLLM Reasoning: è¿­ä»£ç²¾ç‚¼è®­ç»ƒæ¡†æ¶

åŸºäº**è¿­ä»£ç²¾ç‚¼ï¼ˆIterative Refinementï¼‰**ç­–ç•¥çš„ SFT è®­ç»ƒæ¡†æ¶ï¼Œç”¨äºè®­ç»ƒæ‰©æ•£è¯­è¨€æ¨¡å‹è¿›è¡Œæ¨ç†ä»»åŠ¡ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿä¸Šæ‰‹ï¼‰

### 1. å…‹éš†ä»“åº“

```bash
git clone 
```

---

### 2. é…ç½®ç¯å¢ƒ

#### æ–¹å¼ A: åˆ›å»ºæ–°ç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n dllm_env python=3.10
conda activate dllm_env

# å®‰è£…ä¾èµ–
cd dllm_reasoning
pip install -r requirements.txt

# å®‰è£… VERLï¼ˆå¿…éœ€ï¼‰
cd ..
git clone https://github.com/volcengine/verl
cd verl
pip install -e .
cd ../dllm_reasoning
pip install -e .
```

---

### 3. å‡†å¤‡æ•°æ®

#### æ•°æ®æ ¼å¼

è®­ç»ƒæ•°æ®éœ€è¦æ˜¯ **Parquet æ–‡ä»¶**ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š

| åˆ—å | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `prompt` | æŒ‡ä»¤/é—®é¢˜ | "What is 2+2?" |
| `target` | æœŸæœ›çš„è¾“å‡º | "2+2 equals 4." |

#### åˆ›å»ºæ•°æ®æ–‡ä»¶

```python
import pandas as pd

# å‡†å¤‡ä½ çš„æ•°æ®
data = [
    {"prompt": "What is 2+2?", "target": "2+2 equals 4."},
    {"prompt": "Explain gravity", "target": "Gravity is a fundamental force..."},
    # ... æ›´å¤šæ•°æ®
]

# ä¿å­˜ä¸º parquet æ ¼å¼
df = pd.DataFrame(data)
df.to_parquet("train.parquet", index=False)
```

#### æ”¾ç½®æ•°æ®æ–‡ä»¶

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º data æ–‡ä»¶å¤¹
mkdir -p data

# å°†æ•°æ®æ–‡ä»¶æ”¾å…¥ data ç›®å½•
cp /path/to/your/train.parquet data/
```

---

### 4. ä¿®æ”¹é…ç½®ï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ æƒ³ä¿®æ”¹è®­ç»ƒå‚æ•°ï¼Œç¼–è¾‘é…ç½®æ–‡ä»¶ï¼šdllm_reasoning/dllm_reasoning/config/iterative_refine.yaml


**å…³é”®é…ç½®é¡¹ï¼š**

```yaml
data:
  train_files: data/train.parquet      # è®­ç»ƒæ•°æ®è·¯å¾„
  val_files: data/val.parquet          # éªŒè¯æ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼‰
  prompt_key: prompt                    # ä½ çš„æ•°æ®ä¸­çš„ prompt åˆ—å
  response_key: target                  # ä½ çš„æ•°æ®ä¸­çš„ target åˆ—å

model:
  partial_pretrain: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B  # é¢„è®­ç»ƒæ¨¡å‹

trainer:
  total_epochs: 3                       # è®­ç»ƒè½®æ•°
  default_local_dir: ./checkpoints/my_exp  # æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„
```

---

### 5. å¯åŠ¨è®­ç»ƒ

```bash
# ç¡®ä¿åœ¨æ ¹ç›®å½•
cd /path/to

# å¯åŠ¨è®­ç»ƒï¼ˆ4 GPUsï¼‰
bash dllm_reasoning/scripts/train.sh 4 ./checkpoints/my_first_exp

# å• GPU è®­ç»ƒ
bash dllm_reasoning/scripts/train.sh 1 ./checkpoints/my_first_exp

# è‡ªå®šä¹‰å‚æ•°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰
bash dllm_reasoning/scripts/train.sh 4 ./checkpoints/my_exp \
    data.train_files=data/my_data.parquet \
    model.partial_pretrain=meta-llama/Llama-3-8B \
    trainer.total_epochs=5
```

**è®­ç»ƒå¯åŠ¨åä¼šçœ‹åˆ°ï¼š**

```
é¡¹ç›®æ ¹ç›®å½•: /path/to
GPU æ•°é‡: 4
ä¿å­˜ç›®å½•: ./checkpoints/my_first_exp
è¿è¡Œè®­ç»ƒï¼ˆè¾“å‡ºåˆ°ç»ˆç«¯ï¼‰
...
[Epoch 1/3] Step 100/1000: loss=1.234, lr=0.00001
```

---

### 6. æ¨ç†æµ‹è¯•

è®­ç»ƒå®Œæˆåï¼Œæµ‹è¯•ä½ çš„æ¨¡å‹ï¼š

#### æ–¹å¼ A: ä½¿ç”¨æä¾›çš„è„šæœ¬

```bash
# ä¿®æ”¹è„šæœ¬ä¸­çš„é…ç½®
vim dllm_reasoning/scripts/inference.py

# ä¿®æ”¹è¿™ä¸¤è¡Œï¼š
MODEL_PATH = "checkpoints/my_first_exp/global_step_1000/huggingface"
PROMPT = "Your test question here"

# è¿è¡Œæ¨ç†
python dllm_reasoning/scripts/inference.py
```

#### æ–¹å¼ B: ç¼–ç¨‹æ¥å£

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from dllm_reasoning.inference import iterative_generate

# åŠ è½½æ¨¡å‹
model_path = "checkpoints/my_first_exp/global_step_1000/huggingface"
model = AutoModelForCausalLM.from_pretrained(model_path).cuda()
tokenizer = AutoTokenizer.from_pretrained(model_path)

# å‡†å¤‡è¾“å…¥
prompt = "What is 2+2?"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids.cuda()

# ç”Ÿæˆ
output_ids = iterative_generate(
    model=model,
    input_ids=input_ids,
    eos_token_id=tokenizer.eos_token_id,
    pad_token_id=tokenizer.pad_token_id,
    max_new_tokens=512,
)

# è§£ç è¾“å‡º
response = tokenizer.decode(output_ids[0, input_ids.size(1):], skip_special_tokens=True)
print(response)
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

è®­ç»ƒå®Œæˆåï¼Œä½ çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
PATH/                              # é¡¹ç›®æ ¹ç›®å½•
â”œâ”€â”€ dllm_reasoning/                # è®­ç»ƒåŒ…
â”‚   â”œâ”€â”€ dllm_reasoning/           # æ ¸å¿ƒä»£ç 
â”‚   â”‚   â”œâ”€â”€ config/               # é…ç½®æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ trainer/              # è®­ç»ƒå™¨
â”‚   â”‚   â”œâ”€â”€ losses/               # Loss å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”‚   â””â”€â”€ inference/            # æ¨ç†æ¨¡å—
â”‚   â”œâ”€â”€ scripts/                  # å¯åŠ¨è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ setup_env.sh         # ç¯å¢ƒæ¿€æ´»
â”‚   â”‚   â”œâ”€â”€ train.sh             # è®­ç»ƒè„šæœ¬
â”‚   â”‚   â””â”€â”€ inference.py         # æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ setup.py                  # åŒ…é…ç½®
â”‚   â””â”€â”€ requirements.txt          # ä¾èµ–åˆ—è¡¨
â”‚
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•ï¼ˆéœ€è¦åˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ train.parquet             # è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ val.parquet               # éªŒè¯æ•°æ®
â”‚
â”œâ”€â”€ checkpoints/                   # æ£€æŸ¥ç‚¹ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â””â”€â”€ my_first_exp/
â”‚       â”œâ”€â”€ global_step_1000/
â”‚       â”‚   â””â”€â”€ huggingface/      # HuggingFace æ ¼å¼æ¨¡å‹ï¼ˆå¯ç›´æ¥æ¨ç†ï¼‰
â”‚       â””â”€â”€ global_step_2000/
â”‚
â””â”€â”€ log/                           # æ—¥å¿—ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    â””â”€â”€ debug.log                  # è¯¦ç»†è°ƒè¯•æ—¥å¿—
```

---

## âš™ï¸ æ ¸å¿ƒæ¦‚å¿µ

### è¿­ä»£ç²¾ç‚¼è®­ç»ƒæµç¨‹

```
åŸå§‹æ•°æ® (t0): instruction + response

â†“ åŠ å™ª

åŠ å™ªæ•°æ® (s0): instruction + noisy_response (éƒ¨åˆ† token æ›¿æ¢ä¸º EOS)

â†“ å‰å‘ä¼ æ’­

è®¡ç®— loss: loss_s0 = CrossEntropy(model(s0), t0)

â†“ è´ªå©ªè§£ç 

ç²¾ç‚¼æ•°æ® (s1): instruction + refined_response

â†“ å†æ¬¡å‰å‘ä¼ æ’­

è®¡ç®— loss: loss_s1 = CrossEntropy(model(s1), t0)

â†“ èšåˆ

total_loss = loss_s0 + loss_s1
æ¢¯åº¦æ›´æ–°
```

### ä¸æ ‡å‡† SFT çš„åŒºåˆ«

- **æ ‡å‡† SFT**: å•è½®å‰å‘ä¼ æ’­ï¼Œç›´æ¥ä¼˜åŒ–å¹²å‡€æ•°æ®
- **è¿­ä»£ç²¾ç‚¼**: å¤šè½®å‰å‘ä¼ æ’­ï¼Œä»å™ªå£°æ•°æ®é€æ­¥æ¢å¤

---

## ğŸ”§ å¸¸ç”¨é…ç½®

### è°ƒæ•´æ˜¾å­˜å ç”¨

```yaml
# æ–¹æ³• 1: å‡å° batch size
data:
  micro_batch_size_per_gpu: 1  # é»˜è®¤ 2

# æ–¹æ³• 2: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
model:
  enable_gradient_checkpointing: true

# æ–¹æ³• 3: å‡å°‘è¿­ä»£è½®æ•°
iterative:
  num_iterations: 1  # é»˜è®¤ 2
```

### è°ƒæ•´è®­ç»ƒç­–ç•¥

```yaml
iterative:
  num_iterations: 2          # è¿­ä»£è½®æ•°
  noise_min: 0.1            # æœ€å°å™ªå£°æ¯”ä¾‹ï¼ˆ10%ï¼‰
  noise_max: 0.9            # æœ€å¤§å™ªå£°æ¯”ä¾‹ï¼ˆ90%ï¼‰
  loss_weights: [1.0, 1.0]  # æ¯è½® loss æƒé‡

optim:
  lr: 1e-5                  # å­¦ä¹ ç‡
  warmup_steps_ratio: 0.05  # Warmup æ¯”ä¾‹
  clip_grad: 1.0            # æ¢¯åº¦è£å‰ª
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æŠ¥é”™ `No module named dllm_reasoning`

**åŸå› **: æ²¡æœ‰å®‰è£…åŒ…

**è§£å†³**:
```bash
cd dllm_reasoning
pip install -e .
```

### Q2: è®­ç»ƒæ—¶æŠ¥é”™ `No module named verl`

**åŸå› **: VERL æœªå®‰è£…

**è§£å†³**:
```bash
git clone https://github.com/volcengine/verl
cd verl
pip install -e .
```

### Q3: å¦‚ä½•ç›‘æ§è®­ç»ƒ

è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨ï¼š
- ç»ˆç«¯è¾“å‡ºï¼šå®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
- `log/debug.log`ï¼šè¯¦ç»†çš„debugä¿¡æ¯

ä½¿ç”¨ WandB ç›‘æ§ï¼ˆå¯é€‰ï¼‰:
```yaml
trainer:
  logger: ['console', 'wandb']
  project_name: my-project
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§æŒ‡æ ‡

è®­ç»ƒæ—¶ä¼šè¾“å‡ºä»¥ä¸‹æŒ‡æ ‡ï¼š

- `loss_s0`: ç¬¬ä¸€è½®è¿­ä»£çš„ loss
- `loss_s1`: ç¬¬äºŒè½®è¿­ä»£çš„ loss
- `loss_total`: æ€» lossï¼ˆåŠ æƒèšåˆï¼‰
- `grad_norm`: æ¢¯åº¦èŒƒæ•°
- `lr`: å½“å‰å­¦ä¹ ç‡
- `noise_mean`: å¹³å‡å™ªå£°æ¯”ä¾‹

---

## ğŸ¯ è¿›é˜¶ä½¿ç”¨

### æ–­ç‚¹ç»­è®­

```bash
# è®­ç»ƒä¼šè‡ªåŠ¨ä»æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤
bash dllm_reasoning/scripts/train.sh 4 ./checkpoints/my_exp

# æˆ–åœ¨é…ç½®ä¸­æŒ‡å®š
trainer:
  resume_mode: auto  # auto: è‡ªåŠ¨æ¢å¤, disable: ä»å¤´è®­ç»ƒ
```

### è‡ªå®šä¹‰æ•°æ®åˆ—å

å¦‚æœä½ çš„æ•°æ®åˆ—åä¸æ˜¯ `prompt` å’Œ `target`ï¼š

```yaml
data:
  prompt_key: instruction  # ä½ çš„ prompt åˆ—å
  response_key: output     # ä½ çš„ response åˆ—å
```