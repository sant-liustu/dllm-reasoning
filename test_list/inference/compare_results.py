#!/usr/bin/env python3
"""
å¯¹æ¯”æŽ¨ç†ç»“æžœå’ŒåŽŸå§‹ target

ç”¨é€”ï¼š
1. è¯»å–æ‰¹é‡æŽ¨ç†çš„ç»“æžœæ–‡ä»¶ï¼ˆjsonlï¼‰
2. é€æ¡å¯¹æ¯” prediction å’Œ target
3. ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/compare_results.py \
        --results_file results/batch_inference.jsonl \
        --output_file results/comparison_report.txt
"""

import json
import argparse
from pathlib import Path
from difflib import SequenceMatcher


def load_results(results_file):
    """åŠ è½½æŽ¨ç†ç»“æžœ"""
    print(f"ðŸ“‚ åŠ è½½ç»“æžœæ–‡ä»¶: {results_file}")

    results = []
    with open(results_file, 'r', encoding='utf-8') as f:
        for line in f:
            results.append(json.loads(line))

    print(f"   æ€»æ ·æœ¬æ•°: {len(results)}")
    return results


def calculate_similarity(str1, str2):
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰"""
    return SequenceMatcher(None, str1, str2).ratio()


def analyze_results(results, similarity_threshold=0.8):
    """åˆ†æžç»“æžœ"""
    print("\n" + "="*80)
    print("ðŸ“Š è¯¦ç»†åˆ†æž")
    print("="*80)

    total = len(results)
    exact_matches = []
    high_similarity = []
    low_similarity = []

    for result in results:
        target = result['target'].strip()
        prediction = result['prediction'].strip()
        similarity = calculate_similarity(target, prediction)
        result['similarity'] = similarity

        if target == prediction:
            exact_matches.append(result)
        elif similarity >= similarity_threshold:
            high_similarity.append(result)
        else:
            low_similarity.append(result)

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nâœ… å®Œå…¨åŒ¹é…: {len(exact_matches)} / {total} ({len(exact_matches)/total*100:.2f}%)")
    print(f"ðŸŸ¢ é«˜ç›¸ä¼¼åº¦ (>={similarity_threshold}): {len(high_similarity)} / {total} ({len(high_similarity)/total*100:.2f}%)")
    print(f"ðŸ”´ ä½Žç›¸ä¼¼åº¦ (<{similarity_threshold}): {len(low_similarity)} / {total} ({len(low_similarity)/total*100:.2f}%)")

    # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
    avg_similarity = sum(r['similarity'] for r in results) / total
    print(f"\nðŸ“ˆ å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}")

    return {
        'exact_matches': exact_matches,
        'high_similarity': high_similarity,
        'low_similarity': low_similarity,
        'avg_similarity': avg_similarity
    }


def generate_report(results, analysis, output_file, max_display=10):
    """ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š"""
    print(f"\nðŸ’¾ ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š: {output_file}")

    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        # æ ‡é¢˜
        f.write("="*80 + "\n")
        f.write("æ‰¹é‡æŽ¨ç†ç»“æžœå¯¹æ¯”æŠ¥å‘Š\n")
        f.write("="*80 + "\n\n")

        # ç»Ÿè®¡ä¿¡æ¯
        total = len(results)
        f.write("ç»Ÿè®¡ä¿¡æ¯\n")
        f.write("-"*80 + "\n")
        f.write(f"æ€»æ ·æœ¬æ•°: {total}\n")
        f.write(f"å®Œå…¨åŒ¹é…: {len(analysis['exact_matches'])} ({len(analysis['exact_matches'])/total*100:.2f}%)\n")
        f.write(f"é«˜ç›¸ä¼¼åº¦: {len(analysis['high_similarity'])} ({len(analysis['high_similarity'])/total*100:.2f}%)\n")
        f.write(f"ä½Žç›¸ä¼¼åº¦: {len(analysis['low_similarity'])} ({len(analysis['low_similarity'])/total*100:.2f}%)\n")
        f.write(f"å¹³å‡ç›¸ä¼¼åº¦: {analysis['avg_similarity']:.4f}\n")
        f.write("\n")

        # å®Œå…¨åŒ¹é…çš„æ ·æœ¬ï¼ˆæ˜¾ç¤ºå‰å‡ ä¸ªï¼‰
        f.write("="*80 + "\n")
        f.write(f"âœ… å®Œå…¨åŒ¹é…çš„æ ·æœ¬ï¼ˆå‰ {min(max_display, len(analysis['exact_matches']))} ä¸ªï¼‰\n")
        f.write("="*80 + "\n\n")

        for i, result in enumerate(analysis['exact_matches'][:max_display]):
            f.write(f"ã€æ ·æœ¬ {result['index']}ã€‘\n")
            f.write(f"Prompt: {result['prompt']}\n")
            f.write(f"Target: {result['target']}\n")
            f.write(f"Prediction: {result['prediction']}\n")
            f.write(f"ç›¸ä¼¼åº¦: {result['similarity']:.4f}\n")
            f.write("\n" + "-"*80 + "\n\n")

        # é«˜ç›¸ä¼¼åº¦ä½†ä¸å®Œå…¨åŒ¹é…çš„æ ·æœ¬
        f.write("="*80 + "\n")
        f.write(f"ðŸŸ¢ é«˜ç›¸ä¼¼åº¦æ ·æœ¬ï¼ˆå‰ {min(max_display, len(analysis['high_similarity']))} ä¸ªï¼‰\n")
        f.write("="*80 + "\n\n")

        for i, result in enumerate(analysis['high_similarity'][:max_display]):
            f.write(f"ã€æ ·æœ¬ {result['index']}ã€‘\n")
            f.write(f"Prompt: {result['prompt']}\n")
            f.write(f"Target: {result['target']}\n")
            f.write(f"Prediction: {result['prediction']}\n")
            f.write(f"ç›¸ä¼¼åº¦: {result['similarity']:.4f}\n")
            f.write("\n" + "-"*80 + "\n\n")

        # ä½Žç›¸ä¼¼åº¦çš„æ ·æœ¬ï¼ˆéœ€è¦é‡ç‚¹å…³æ³¨ï¼‰
        f.write("="*80 + "\n")
        f.write(f"ðŸ”´ ä½Žç›¸ä¼¼åº¦æ ·æœ¬ï¼ˆå‰ {min(max_display, len(analysis['low_similarity']))} ä¸ªï¼‰âš ï¸ éœ€è¦é‡ç‚¹å…³æ³¨\n")
        f.write("="*80 + "\n\n")

        for i, result in enumerate(analysis['low_similarity'][:max_display]):
            f.write(f"ã€æ ·æœ¬ {result['index']}ã€‘\n")
            f.write(f"Prompt: {result['prompt']}\n")
            f.write(f"Target: {result['target']}\n")
            f.write(f"Prediction: {result['prediction']}\n")
            f.write(f"ç›¸ä¼¼åº¦: {result['similarity']:.4f}\n")
            f.write("\n" + "-"*80 + "\n\n")

        # ç›¸ä¼¼åº¦åˆ†å¸ƒ
        f.write("="*80 + "\n")
        f.write("ðŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒ\n")
        f.write("="*80 + "\n\n")

        bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]
        for i in range(len(bins)-1):
            count = sum(1 for r in results if bins[i] <= r['similarity'] < bins[i+1])
            if i == len(bins)-2:  # æœ€åŽä¸€ä¸ªåŒºé—´åŒ…å« 1.0
                count = sum(1 for r in results if bins[i] <= r['similarity'] <= bins[i+1])
            f.write(f"[{bins[i]:.1f}, {bins[i+1]:.1f}]: {count} ({count/total*100:.2f}%)\n")

    print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜")


def main():
    parser = argparse.ArgumentParser(description="å¯¹æ¯”æŽ¨ç†ç»“æžœå’ŒåŽŸå§‹ target")

    parser.add_argument("--results_file", type=str, required=True,
                       help="æŽ¨ç†ç»“æžœæ–‡ä»¶ï¼ˆjsonl æ ¼å¼ï¼‰")
    parser.add_argument("--output_file", type=str,
                       default="results/comparison_report.txt",
                       help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--similarity_threshold", type=float, default=0.8,
                       help="é«˜ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤: 0.8ï¼‰")
    parser.add_argument("--max_display", type=int, default=10,
                       help="æ¯ä¸ªç±»åˆ«æœ€å¤šæ˜¾ç¤ºçš„æ ·æœ¬æ•°ï¼ˆé»˜è®¤: 10ï¼‰")

    args = parser.parse_args()

    print("="*80)
    print("ðŸ” ç»“æžœå¯¹æ¯”åˆ†æž")
    print("="*80)

    # 1. åŠ è½½ç»“æžœ
    results = load_results(args.results_file)

    # 2. åˆ†æžç»“æžœ
    analysis = analyze_results(results, args.similarity_threshold)

    # 3. ç”ŸæˆæŠ¥å‘Š
    generate_report(results, analysis, args.output_file, args.max_display)

    print("\n" + "="*80)
    print("âœ… åˆ†æžå®Œæˆï¼")
    print(f"   æŠ¥å‘Šæ–‡ä»¶: {args.output_file}")
    print("="*80)


if __name__ == "__main__":
    main()
