#!/usr/bin/env python3
"""
ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹æµ‹è¯•æœ€å°truncation

æµ‹è¯•é…ç½®ï¼š
1. [P][Mâ‚] - åªæœ‰ç¬¬ä¸€ä¸ªmask block
2. [P][Mâ‚][Râ‚] - ç¬¬ä¸€ä¸ªmask + ç¬¬ä¸€ä¸ªreal
3. [P][Mâ‚][Râ‚][Mâ‚‚] - å‰3ä¸ªblock
4. å®Œæ•´åºåˆ—

ç›®æ ‡ï¼šéªŒè¯ Mâ‚ çš„è¾“å‡ºæ˜¯å¦ä¸å—åé¢ block çš„å½±å“
"""

import os
os.environ["TORCH_COMPILE_DISABLE"] = "1"

import sys
from pathlib import Path
import torch
from transformers import AutoTokenizer

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from dllm_reasoning.trainer.interleaved_sft_dataset import InterleavedSFTDataset
from dllm_reasoning.model.DLLM.modeling_dllm import DLLMForCausalLM
from dllm_reasoning.model.DLLM.configuration_dllm import DLLMConfig


def test_with_truncation(
    model,
    tokenizer,
    sample,
    num_blocks_to_keep: int,
    device: str = "cuda",
):
    """
    æµ‹è¯•ä¿ç•™å‰Nä¸ªblockæ—¶çš„å‡†ç¡®ç‡

    Args:
        model: æ¨¡å‹
        tokenizer: tokenizer
        sample: æ•°æ®é›†æ ·æœ¬
        num_blocks_to_keep: ä¿ç•™å¤šå°‘ä¸ªblock
        device: è®¾å¤‡

    Returns:
        å‰3ä¸ªMask blockçš„å‡†ç¡®ç‡åˆ—è¡¨
    """
    input_ids = sample['input_ids'].to(device)
    position_ids = sample['position_ids'].to(device)
    labels = sample['labels'].to(device)
    block_info = sample['block_info']
    prompt_len = sample['prompt_len']

    # æˆªæ–­block_infoå’Œåºåˆ—
    # è®¡ç®—è¦ä¿ç•™çš„åºåˆ—é•¿åº¦
    current_pos = prompt_len
    blocks_seen = 0
    truncate_pos = None

    for seg_type, seg_idx, seg_len in block_info:
        blocks_seen += 1
        current_pos += seg_len
        if blocks_seen >= num_blocks_to_keep:
            truncate_pos = current_pos
            break

    if truncate_pos is None:
        truncate_pos = input_ids.size(0)

    # æˆªæ–­åºåˆ—
    input_ids_truncated = input_ids[:truncate_pos]
    position_ids_truncated = position_ids[:truncate_pos]
    labels_truncated = labels[:truncate_pos]

    # æˆªæ–­block_info - ä¿æŒå®Œæ•´çš„ä¸‰å…ƒç»„ (seg_type, seg_idx, seg_len)
    block_info_truncated = []
    blocks_added = 0
    for seg_type, seg_idx, seg_len in block_info:
        if blocks_added >= num_blocks_to_keep:
            break
        block_info_truncated.append((seg_type, seg_idx, seg_len))
        blocks_added += 1

    # å‰å‘ä¼ æ’­ - ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids_truncated.unsqueeze(0),
            position_ids=position_ids_truncated.unsqueeze(0),
            block_info=[block_info_truncated],
            prompt_len=[prompt_len],
            seq_lens=[truncate_pos],
            use_cache=False
        )
        logits = outputs.logits

    predictions = logits[0].argmax(dim=-1)
    labels_1d = labels_truncated

    # ç»Ÿè®¡å‰3ä¸ªMask blockçš„å‡†ç¡®ç‡
    mask_block_accs = []
    current_pos = prompt_len
    mask_block_count = 0

    for seg_type, seg_idx, seg_len in block_info_truncated:
        if seg_type == 'mask' and mask_block_count < 3:
            # è®¡ç®—è¿™ä¸ªmask blockçš„å‡†ç¡®ç‡
            mask_labels = labels_1d[current_pos:current_pos+seg_len]
            mask_preds = predictions[current_pos:current_pos+seg_len]
            valid = mask_labels != -100

            if valid.sum() > 0:
                correct = ((mask_preds == mask_labels) & valid).sum().item()
                total = valid.sum().item()
                acc = correct / total
                mask_block_accs.append(acc)
                mask_block_count += 1

        current_pos += seg_len

    return mask_block_accs


def main():
    MODEL_PATH = "dllm_reasoning/dllm_reasoning/models/DLLM-1.5B"
    DATA_PATH = "data/openr1.parquet"

    print("="*80)
    print("ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹æµ‹è¯• Mâ‚ æ˜¯å¦å—åç»­blockå½±å“")
    print("="*80)
    print()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print("åŠ è½½ä¿®å¤åçš„æœ¬åœ°æ¨¡å‹...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)

    # ä»æœ¬åœ°ä»£ç åŠ è½½æ¨¡å‹
    config = DLLMConfig.from_pretrained(MODEL_PATH)
    model = DLLMForCausalLM(config)

    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    from transformers import AutoModelForCausalLM
    pretrained = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        torch_dtype=torch.bfloat16,
        trust_remote_code=True,
    )
    model.load_state_dict(pretrained.state_dict())
    model = model.to(device).to(torch.bfloat16)

    # ä½¿ç”¨è®­ç»ƒæ¨¡å¼
    model.train()

    print("åŠ è½½æ•°æ®é›†...")
    dataset = InterleavedSFTDataset(
        parquet_files=DATA_PATH,
        tokenizer=tokenizer,
        prompt_key="prompt",
        response_key="target",
        block_size=4,
        max_length=6000,
        truncation="right",
    )

    sample = dataset[0]

    print(f"æ ·æœ¬ä¿¡æ¯:")
    print(f"  æ€»åºåˆ—é•¿åº¦: {sample['input_ids'].shape[0]}")
    print(f"  Prompté•¿åº¦: {sample['prompt_len']}")
    print(f"  æ€»Blockæ•°: {len(sample['block_info'])}")

    # ç»Ÿè®¡æ€»å…±æœ‰å¤šå°‘ä¸ªmask block
    total_mask_blocks = sum(1 for seg_type, _, _ in sample['block_info'] if seg_type == 'mask')
    print(f"  æ€»Mask blocks: {total_mask_blocks}\n")

    print(f"{'='*80}")
    print(f"æ¸è¿›å¼æˆªæ–­æµ‹è¯•ï¼šç†è§£å“ªä¸ªblockå½±å“Mâ‚çš„é¢„æµ‹")
    print(f"{'='*80}\n")

    # æµ‹è¯•å››ä¸ªé…ç½®
    test_configs = [
        1,    # [P][Mâ‚]
        2,    # [P][Mâ‚][Râ‚]
        3,    # [P][Mâ‚][Râ‚][Mâ‚‚]
        len(sample['block_info']),  # å®Œæ•´åºåˆ—
    ]

    results = []

    for num_blocks in test_configs:
        if num_blocks > len(sample['block_info']):
            continue

        print(f"æµ‹è¯•é…ç½®: ä¿ç•™å‰ {num_blocks} ä¸ªblocks...")

        mask_accs = test_with_truncation(
            model=model,
            tokenizer=tokenizer,
            sample=sample,
            num_blocks_to_keep=num_blocks,
            device=device,
        )

        # è®¡ç®—å‰3ä¸ªmask blockçš„å¹³å‡å‡†ç¡®ç‡
        if len(mask_accs) > 0:
            avg_acc = sum(mask_accs) / len(mask_accs)
        else:
            avg_acc = 0.0

        results.append({
            'num_blocks': num_blocks,
            'mask_accs': mask_accs,
            'avg_acc': avg_acc,
        })

        print(f"  å‰3ä¸ªMask blockå‡†ç¡®ç‡: {mask_accs}")
        print(f"  å¹³å‡: {avg_acc:.4f}")
        print()

    # æ€»ç»“
    print(f"\n{'='*80}")
    print(f"æ¸è¿›å¼å¯¹æ¯”ï¼šç¬¬ä¸€ä¸ªMask blockï¼ˆMâ‚ï¼‰çš„å‡†ç¡®ç‡å˜åŒ–")
    print(f"{'='*80}\n")

    # æå–æ‰€æœ‰é…ç½®çš„Mâ‚å‡†ç¡®ç‡
    config_names = [
        "[P][Mâ‚]",
        "[P][Mâ‚][Râ‚]",
        "[P][Mâ‚][Râ‚][Mâ‚‚]",
        f"å®Œæ•´åºåˆ—({results[-1]['num_blocks']}å—)" if len(results) >= 4 else "å®Œæ•´åºåˆ—"
    ]

    print(f"{'é…ç½®':^30} | {'Mâ‚å‡†ç¡®ç‡':^15}")
    print(f"{'-'*50}")

    m1_accs = []
    for i, r in enumerate(results):
        m1_acc = r['mask_accs'][0] if len(r['mask_accs']) > 0 else 0
        m1_accs.append(m1_acc)
        config_name = config_names[i] if i < len(config_names) else f"{r['num_blocks']}å—"
        print(f"{config_name:^30} | {m1_acc:>8.4f} ({m1_acc*100:>6.2f}%)")

    # åˆ†æ
    print(f"\n{'='*80}")
    print(f"åˆ†æ")
    print(f"{'='*80}\n")

    if len(m1_accs) >= 3:
        only_m1 = m1_accs[0]
        with_r1 = m1_accs[1]
        with_m2 = m1_accs[2]
        full = m1_accs[-1]

        print(f"1ï¸âƒ£  [P][Mâ‚] â†’ [P][Mâ‚][Râ‚]:")
        diff1 = with_r1 - only_m1
        print(f"   å‡†ç¡®ç‡å˜åŒ–: {diff1:+.4f} ({diff1/only_m1*100 if only_m1 > 0 else 0:+.2f}%)")
        if abs(diff1) < 0.01:
            print(f"   âœ… Râ‚å¯¹Mâ‚åŸºæœ¬æ— å½±å“")
        elif diff1 > 0:
            print(f"   âš ï¸ Râ‚æå‡äº†Mâ‚çš„å‡†ç¡®ç‡")
        else:
            print(f"   âš ï¸ Râ‚é™ä½äº†Mâ‚çš„å‡†ç¡®ç‡")
        print()

        print(f"2ï¸âƒ£  [P][Mâ‚][Râ‚] â†’ [P][Mâ‚][Râ‚][Mâ‚‚]:")
        diff2 = with_m2 - with_r1
        print(f"   å‡†ç¡®ç‡å˜åŒ–: {diff2:+.4f} ({diff2/with_r1*100 if with_r1 > 0 else 0:+.2f}%)")
        if abs(diff2) < 0.01:
            print(f"   âœ… Mâ‚‚å¯¹Mâ‚åŸºæœ¬æ— å½±å“")
        elif diff2 > 0:
            print(f"   âš ï¸ Mâ‚‚æå‡äº†Mâ‚çš„å‡†ç¡®ç‡")
        else:
            print(f"   âš ï¸ Mâ‚‚é™ä½äº†Mâ‚çš„å‡†ç¡®ç‡")
        print()

        print(f"3ï¸âƒ£  [P][Mâ‚][Râ‚][Mâ‚‚] â†’ å®Œæ•´åºåˆ—:")
        diff3 = full - with_m2
        print(f"   å‡†ç¡®ç‡å˜åŒ–: {diff3:+.4f} ({diff3/with_m2*100 if with_m2 > 0 else 0:+.2f}%)")
        if abs(diff3) < 0.01:
            print(f"   âœ… åç»­blockï¼ˆRâ‚‚Mâ‚ƒ...ï¼‰å¯¹Mâ‚åŸºæœ¬æ— å½±å“")
        elif diff3 > 0:
            print(f"   âš ï¸ åç»­blockæå‡äº†Mâ‚çš„å‡†ç¡®ç‡")
        else:
            print(f"   âš ï¸ åç»­blocké™ä½äº†Mâ‚çš„å‡†ç¡®ç‡")
        print()

        print(f"{'='*80}")
        print(f"å…³é”®å‘ç°")
        print(f"{'='*80}\n")

        # æ£€æŸ¥æ‰€æœ‰å·®å¼‚æ˜¯å¦éƒ½å¾ˆå°
        max_diff = max(abs(diff1), abs(diff2), abs(diff3))

        if max_diff < 0.01:
            print(f"âœ… æ‰€æœ‰é…ç½®ä¸‹Mâ‚çš„å‡†ç¡®ç‡åŸºæœ¬ç›¸åŒï¼ˆæœ€å¤§å·®å¼‚: {max_diff:.4f}ï¼‰")
            print(f"\nè¿™è¯´æ˜ï¼š")
            print(f"  - BlockMaskæ­£ç¡®å·¥ä½œï¼ŒMâ‚çœ‹ä¸åˆ°åç»­çš„token")
            print(f"  - åç»­blockä¸å½±å“Mâ‚çš„é¢„æµ‹")
            print(f"  - æ¨¡å‹ä¿®å¤æˆåŠŸï¼")
        else:
            # æ‰¾å‡ºå½±å“æœ€å¤§çš„å˜åŒ–
            diffs = [
                ("æ·»åŠ Râ‚", diff1),
                ("æ·»åŠ Mâ‚‚", diff2),
                ("æ·»åŠ åç»­blocks", diff3)
            ]
            max_diff_item = max(diffs, key=lambda x: abs(x[1]))

            print(f"âš ï¸ å‘ç°æ˜¾è‘—å·®å¼‚ï¼")
            print(f"\nå¯¹Mâ‚å½±å“æœ€å¤§çš„æ˜¯ï¼š{max_diff_item[0]}")
            print(f"å½±å“ç¨‹åº¦: {max_diff_item[1]:+.4f}")

            if abs(diff2) > 0.01 and diff2 < 0:
                print(f"\nğŸ” é‡è¦ï¼šMâ‚‚çš„å­˜åœ¨æ˜¾è‘—é™ä½äº†Mâ‚çš„å‡†ç¡®ç‡ï¼")
                print(f"   è¿™å¯èƒ½è¯´æ˜BlockMaskä»æœ‰é—®é¢˜")

    print(f"\n{'='*80}")


if __name__ == "__main__":
    main()
